[{"title":"Two-level dynamic scheduling in PARDISO: Improved scalability on shared memory multiprocessing systems","type":"journal","authors":[{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Klaus","last_name":"Gärtner","scopus_author_id":"7005597145"}],"year":2002,"source":"Parallel Computing","identifiers":{"pii":"S0167819101001351","sgr":"0036467538","scopus":"2-s2.0-0036467538","pui":"34086589","issn":"01678191","doi":"10.1016/S0167-8191(01)00135-1"},"keywords":["Large sparse linear systems","Multiprocessor computers","Parallel sparse solvers","Sparse LU decomposition","Sparse matrix factorization"],"id":"85bbd273-d64c-3c6e-839c-9858c6b3eb98","abstract":"The PARDISO package is a mathematical library of OpenMP routines for the parallel direct solution of large sparse linear systems of equations. One objective of PARDISO is to achieve a high efficiency on shared memory multiprocessing systems. A new parallelization strategy based on a dynamic two-level scheduling scheme is therefore explored. The method aims at minimizing cache conflicts and interprocessor communication costs and, at the same time, maximizing processor load balance and Level-3 BLAS performance. The synchronization events are reduced by one order of magnitude compared with a one-level scheduling strategy. This results in an efficient parallel sparse LU decomposition method. An overview of the two-level scheduling algorithm and the key algorithmic features of the solver PARDISO is given. Finally, numerical results and a comparison with another software package demonstrate the performance. © 2002 Published by Elsevier Science B.V.","link":"http://www.mendeley.com/research/twolevel-dynamic-scheduling-pardiso-improved-scalability-shared-memory-multiprocessing-systems"},{"title":"[The living will. An analysis of state of knowledge of patients in the HELIOS hospital Leisnig].","type":"journal","authors":[{"first_name":"Vinzent","last_name":"Piechaczek"},{"first_name":"Olaf","last_name":"Schenk"}],"year":2014,"source":"Pflege Zeitschrift","identifiers":{"issn":"0945-1129","pmid":"24720170"},"id":"cd19bbb4-7195-374f-b8fd-2e6c4471a70f","abstract":"On September 1, 2009, the Guardianship Law (Betreuungsgesetz) changed for the third time. Thus, the rights of the people living in Germany have been improved with reference to the preventive instruments. The aim of the work was to find about the subject to what extent patients understand the subject and how many of them have such a preventive document. The area of research has been examined on the basis of a standardized questionnaire drawn up by means of anonymous data collection in the quantitative research design. After the pretest, the survey was done in form of a documented Face-to-face-questioning in the HELIOS hospital Leisnig. The sample size comprised 139 patients from which 84 patients (37 female, 47 male) agreed with the survey. 25 percent of the questioned patients knew the law of living will (Patientenverfügungsgesetz) and 27 percent knew about the content of preventive instruments. 46.4 percent of the surveyed patients, aged between 70 and 75, had at least one preventive instrument. 63.1 percent of the patients believed that a living will has to be in a written form. 21.4 percent said that, in addition, the document has to be authenticated by a notary public. A study by van Oorschot claims that between ten and 15 percent of the people living in Germany have a living will (van Oorschot 2008, p. 443, Sahm & Schroeder 2009, p. 98). The results of this study show a much higher proportion of existing living wills. For the majority of respondents a preventive instrument plays still a minor role, but 46 percent of the population already use a preventive instrument to make provisions for themselves. 27 percent did express their will in theform of a living will. Nevertheless, the survey shows a lack of knowledge of the correct handling of the living will.","link":"http://www.mendeley.com/research/living-analysis-state-knowledge-patients-helios-hospital-leisnig"},{"title":"Parallel Sparse Direct Solver PARDISO — User Guide","type":"journal","authors":[{"first_name":"Olaf","last_name":"Schenk"},{"first_name":"Klaus","last_name":"Gartner"}],"year":2014,"source":"PARDISO Project","id":"53acf85e-660c-370f-a653-9f4c807458b3","abstract":"The package PARDISO is a high-performance, robust, memory{e\u000Ecient and easy to use software for solving large sparse symmetric and nonsymmetric linear systems of equations on shared{memory and distributed-memory architectures. The solver uses a combination of left- and right-looking Level-3 BLAS supernode techniques [15]. In order to improve sequential and parallel sparse numerical factorization performance, the algorithms are based on a Level-3 BLAS update, and pipelining parallelism is exploited with a combination of left- and right-looking supernode techniques [9, 11, 12, 14]. The parallel pivoting methods allow complete supernode pivoting in order to balance numerical stability and scalability during the factorization process. For su\u000Eciently large problem sizes, numerical experiments demonstrate that the scalability of the parallel algorithm is nearly independent of the shared-memory and distributed-memory multiprocessing architecture and a speedup of up to seven using eight processors has been observed. The approach is based on OpenMP [4] directives and MPI parallelization, and has been successfully tested on almost all shared-memory parallel systems.","link":"http://www.mendeley.com/research/parallel-sparse-direct-solver-pardiso-user-guide"},{"title":"Constraint handling for gradient-based optimization of compositional reservoir flow","type":"journal","authors":[{"first_name":"Drosos","last_name":"Kourounis","scopus_author_id":"15735165800"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"}],"year":2015,"source":"Computational Geosciences","identifiers":{"issn":"15731499","sgr":"84952631629","doi":"10.1007/s10596-015-9524-5","scopus":"2-s2.0-84952631629","pui":"606025876"},"keywords":["Adjoint formulation","Automatic differentiation","Compositional reservoir simulation","Continuous adjoint","Discrete adjoint","General constraints","Gradient-based optimization","Nonlinear constraints","Production optimization","Recovery optimization"],"id":"80cd1010-4648-3b65-becc-35e2154f33a8","abstract":"An adjoint formulation for the gradient-based optimization of oil-gas compositional reservoir simulation problems is presented. The method is implemented within an automatic differentiation-based compositional flow simulator (Stanford's Automatic Differentiation-based General Purpose Research Simulator, AD-GPRS). The development of adjoint procedures for general compositional problems is much more challenging than for oil-water problems due to the increased complexity of the code and the underlying physics. The treatment of nonlinear constraints, an example of which is a maximum gas rate specification in injection or production wells, when the control variables are well bottom-hole pressures, poses a particular challenge. Two approaches for handling these constraints are presented-a formal treatment within the optimizer and a simpler heuristic treatment in the forward model. The relationship between discrete and continuous adjoint formulations is also elucidated. Results for four example cases of increasing complexity are presented. Improvements in the objective function (cumulative oil produced) relative to reference solutions range from 4.2 to 11.6 %. The heuristic treatment of nonlinear constraints is shown to offer a cost-effective means for obtaining feasible solutions, which are, in some cases, better than those obtained using the formal constraint handling procedure. © 2014 Springer Science+Business Media Dordrecht.","link":"http://www.mendeley.com/research/constraint-handling-gradientbased-optimization-compositional-reservoir-flow"},{"title":"Gate-stack engineering in n-type Ultrascaled SI Nanowire field-effect transistors","type":"journal","authors":[{"first_name":"Mathieu","last_name":"Luisier","scopus_author_id":"14421377700"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"}],"year":2013,"source":"IEEE Transactions on Electron Devices","identifiers":{"issn":"00189383","sgr":"84884757359","doi":"10.1109/TED.2013.2278573","scopus":"2-s2.0-84884757359","pui":"369915190"},"keywords":["Device scaling","gate leakage","quantum transport simulation"],"id":"23ff347b-aec9-3e36-8d52-445eb680d8f8","abstract":"— The electrical properties of gate-stacks composed of an interfacial SiO x layer and different types of high-κ dielectrics are theoretically investigated for potential applications as oxide layers in ultrascaled Si nanowire field-effect transistors with a gate length of 5 nm. As a simulation tool, a 3-D quantum transport solver based on the effective mass approximation and including gate leakage currents is employed. We determine how the dielectric constant of the high-κ layer and its conduction band offset with Si must be engineered so that an equivalent oxide thickness of 0.5–0.6 nm can be achieved while maintaining the transistor OFF-state current < 0.1 μA/μm.","link":"http://www.mendeley.com/research/gatestack-engineering-ntype-ultrascaled-si-nanowire-fieldeffect-transistors"},{"title":"Optimal design of metal forming die surfaces with evolution strategies","type":"journal","authors":[{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Matthias","last_name":"Hillmann","scopus_author_id":"6602833717"}],"year":2004,"source":"Computers and Structures","identifiers":{"issn":"00457949","sgr":"3142575443","doi":"10.1016/j.compstruc.2004.03.055","pii":"S0045794904001099","scopus":"2-s2.0-3142575443","pui":"38897651"},"keywords":["Distributed computing","Finite-element simulation","Integrated evolution strategies","Metal forming process","Optimization","Structural optimization"],"id":"dd79c617-c75f-3888-bc18-16bbd8ddbc00","abstract":"A common characteristics in the simulation of automotive sheet metal forming processes is that nearly all die surfaces are manually created within conventional computer-aided design systems (CAD). The solutions produced using these CAD systems are undoubtedly valuable from the point of view of applicability in sheet metal forming practice. However, this approach is time consuming and most of the design time is spent within these CAD systems. This paper presents the development of a computer-based approach for the evolutionary automatic design (EAD) of geometry and process parameters for industrial metal forming processes. The main characteristics of the solution methodology are the use of evolution strategies within the optimizer, the use of sheet metal formability as objective functions and a parameterization of die surfaces. The results of a comparative study of our EAD die surface generation against conventional CAD die surface generation for a representative structural design problem show the efficiency of the former. It is observed that EAD often finds the region of the search space containing the global optimum, thus supporting engineers in practice with automatic generated sheet metal forming tools. © 2004 Elsevier Ltd. All rights reserved.","link":"http://www.mendeley.com/research/optimal-design-metal-forming-die-surfaces-evolution-strategies"},{"title":"Advancing crash forming analysis capabilities through solver technology","type":"book_section","authors":[{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Mike","last_name":"Selig","scopus_author_id":"56845022400"}],"year":2003,"source":"Computational Fluid and Solid Mechanics 2003","identifiers":{"pii":"B9780080440460501548","sgr":"84941695430","scopus":"2-s2.0-84941695430","pui":"606033445","isbn":"9780080529479","doi":"10.1016/B978-008044046-0.50154-8"},"keywords":["Crash forming","Direct solvers","Finite elements","Implicit integration"],"id":"cee77264-9f71-304d-8f5f-ca2161ec5578","abstract":"This paper describes substantial improvements in analysis capabilities in a large commercial finite element program made possible by the integration of modem sparse direct solver technology. The research on symmetric and general unsymmetric sparse systems of linear equations was a very active area during the past few years and recent algorithmic improvements alone have reduced the time required for the direct solution of synometric and general unsymmetric sparse systems of linear equations by almost one order of magnitude. The paper will briefly describe the direct solver technology, discuss the various algorithmic components of some well-known solver packages, and compare resource requirements of these solvers for large sparse finite-element matrices. In addition, the paper will also present comparative results from an industrial crash forming analysis.","link":"http://www.mendeley.com/research/advancing-crash-forming-analysis-capabilities-through-solver-technology"},{"title":"A performance study of an anelastic wave propagation code using auto-tuned stencil computations","type":"conference_proceedings","authors":[{"first_name":"Matthias","last_name":"Christen","scopus_author_id":"55225332000"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"}],"year":2012,"source":"Procedia Computer Science","identifiers":{"issn":"18770509","sgr":"84896982306","doi":"10.1016/j.procs.2012.04.102","pii":"S1877050912002232","scopus":"2-s2.0-84896982306","pui":"372697948"},"keywords":["Auto-tuning","Finite differences","Stencil computations","Wave propagation"],"id":"bd3a9729-c541-3ccb-9d17-606b37da9057","abstract":"In this paper, we use our stencil code generation and auto-tuning framework PATUS to optimize and parallelize the most compute intensive stencil calculations of an anelastic wave propagation code, which was used to conduct numerous significant simulations at the Southern California Earthquake Center. From a straight-forward specification of the stencil calculation, PATUS automatically creates an implementation targeted at the chosen hardware platform and applies hardware-specific optimizations including cache blocking, loop unrolling, and explicit vectorization. We show that, using this approach, we are able to speed up individual compute kernels by a factor of 2.4× on average, and reduce the time required to compute one time step of the entire simulation by 47% in a weak and up to 129% in a strong thread scaling setting. © 2012 Published by Elsevier Ltd.","link":"http://www.mendeley.com/research/performance-study-anelastic-wave-propagation-code-using-autotuned-stencil-computations"},{"title":"Solving unsymmetric sparse systems of linear equations with PARDISO","type":"conference_proceedings","authors":[{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Klaus","last_name":"G̈artner","scopus_author_id":"7005597145"}],"year":2004,"source":"Future Generation Computer Systems","identifiers":{"issn":"0167739X","sgr":"1642370513","doi":"10.1016/j.future.2003.07.011","pii":"S0167739X03001882","isbn":"3-540-43593-X","scopus":"2-s2.0-1642370513","pui":"38396603"},"keywords":["Computational sciences","Direct solver","Numerical linear algebra","Unsymmetric linear systems"],"id":"3eec714c-9506-3c03-baac-ed8f854c0fc2","abstract":"Supernode partitioning for unsymmetric matrices together with complete block diagonal supernode pivoting and asynchronous computation can achieve high gigaflop rates for parallel sparse LU factorization on shared memory parallel computers. The progress in weighted graph matching algorithms helps to extend these concepts further and unsymmetric prepermutation of rows is used to place large matrix entries on the diagonal. Complete block diagonal supernode pivoting allows dynamical interchanges of columns and rows during the factorization process. The level-3 BLAS efficiency is retained and an advanced two-level left-right looking scheduling scheme results in good speedup on SMP machines. These algorithms have been integrated into the recent unsymmetric version of the PARDISO solver. Experiments demonstrate that a wide set of unsymmetric linear systems can be solved and high performance is consistently achieved for large sparse unsymmetric matrices from real world applications. © 2003 Elsevier B.V. All rights reserved.","link":"http://www.mendeley.com/research/solving-unsymmetric-sparse-systems-linear-equations-pardiso"},{"title":"On fast factorization pivoting methods for sparse symmetric indefinite systems","type":"journal","authors":[{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Klaus","last_name":"Gärtner","scopus_author_id":"7005597145"}],"year":2006,"source":"Electronic Transactions on Numerical Analysis","identifiers":{"isbn":"1068-9613","scopus":"2-s2.0-33846230007","issn":"10689613","pui":"46092256","sgr":"33846230007"},"keywords":["Direct solver","Graph algorithms","Interior point optimization","Pivoting","Sparse matrices","Symmetric indefinite matrix"],"id":"7d2a8d41-17f5-3afd-8c32-46e4f143d61b","abstract":"This paper discusses new pivoting factorization methods for solving sparse symmetric indefinite systems. As opposed to many existing pivoting methods, our Supernode-Bunch-Kaufmnan (SBK) pivoting method dynamically selects 1×1 and 2×2 pivots and may be supplemented by pivot perturbation techniques. We demonstrate the effectiveness and the numerical accuracy of this algorithm and also show that a high performance implementation is feasible. We will also show that symmetric maximum-weighted matching strategies add an additional level of reliability to SBK. These techniques can be seen as a complement to the alternative idea of using more complete pivoting techniques during the numerical factorization. Numerical experiments validate these conclusions. Copyright © 2006, Kent State University.","link":"http://www.mendeley.com/research/fast-factorization-pivoting-methods-sparse-symmetric-indefinite-systems"},{"title":"Fast methods for computing selected elements of the Green's function in massively parallel nanoelectronic device simulations","type":"conference_proceedings","authors":[{"first_name":"Andrey","last_name":"Kuzmin","scopus_author_id":"55839650700"},{"first_name":"Mathieu","last_name":"Luisier","scopus_author_id":"14421377700"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"}],"year":2013,"source":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","identifiers":{"sgr":"84883173485","scopus":"2-s2.0-84883173485","pui":"369682387","isbn":"9783642400469","issn":"03029743","doi":"10.1007/978-3-642-40047-6_54"},"id":"4baec25c-dd0b-31e5-8713-2ca65c1184a1","abstract":"The central computation in atomistic, quantum transport simulation consists in solving the Schrödinger equation several thousand times with non-equilibrium Green's function (NEGF) equations. In the NEGF formalism, a numerical linear algebra problem is identified re-lated to the computation of a sparse inverse subset of general sparse un-symmetric matrices. The computational challenge consists in computing all the diagonal entries of the Green's functions, which represent the in-verse of the electron Hamiltonian matrix. Parallel upward and downward traversals of the elimination tree are used to perform these computations very efficiently and reduce the overall simulation time for realistic nano-electronic devices. Extensive large-scale numerical experiments on the CRAY-XE6 Monte Rosa at the Swiss National Supercomputing Center and on the BG/Q at the Argonne Leadership Computing Facility are presented.","link":"http://www.mendeley.com/research/fast-methods-computing-selected-elements-greens-function-massively-parallel-nanoelectronic-device-si"},{"title":"The Effects of Unsymmetric Matrix Permutations and Scalings in Semiconductor Device and Circuit Simulation","type":"journal","authors":[{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Stefan","last_name":"Röllin","scopus_author_id":"36895210200"},{"first_name":"Anshul","last_name":"Gupta","scopus_author_id":"55491956100"}],"year":2004,"source":"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","identifiers":{"sgr":"12144289985","scopus":"2-s2.0-12144289985","pui":"38378933","issn":"02780070","doi":"10.1109/TCAD.2004.823345"},"keywords":["Circuit simulation","Numerical linear algebra","Preconditioning","Semiconductor device simulation","Sparse linear solvers","Sparse unsymmetric matrices"],"id":"eb9e4934-eacf-3956-91f4-2bd6d3faa7c6","abstract":"The solution of large sparse unsymmetric linear systems is a critical and challenging component of semiconductor device and circuit simulations. The time for a simulation is often dominated by this part. The sparse solver is expected to balance different, and often conflicting requirements. Reliability, a low memory-footprint, and a short solution time are a few of these demands. Currently, no black-box solver exists that can satisfy all criteria. The linear systems from both simulations can be highly ill-conditioned and are, therefore, quite challenging for direct and iterative methods. In this paper, it is shown that algorithms to place large entries on the diagonal using unsymmetric permutations and scalings greatly enhance the reliability of both direct and preconditioned iterative solvers for unsymmetric linear systems arising in semiconductor device and circuit simulations. The numerical experiments indicate that the overall solution strategy is both reliable and cost effective.","link":"http://www.mendeley.com/research/effects-unsymmetric-matrix-permutations-scalings-semiconductor-device-circuit-simulation"},{"title":"Real-time stochastic optimization of complex energy systems on high-performance computers","type":"journal","authors":[{"first_name":"Cosmin G.","last_name":"Petra","scopus_author_id":"26635643900"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Mihai","last_name":"Anitescu","scopus_author_id":"6604042478"}],"year":2014,"source":"Computing in Science and Engineering","identifiers":{"isbn":"9781467308069","scopus":"2-s2.0-84908137102","issn":"15219615","pui":"600201378","sgr":"84908137102","doi":"10.1109/MCSE.2014.53"},"keywords":["continuation (homotopy) methods","distributed programming","high-performance computing","linear systems","scientific computing","stochastic programming"],"id":"3e84d04f-bd0d-3ea3-8750-66459ce084c8","abstract":"A scalable approach computes in operationally-compatible time the energy dispatch under uncertainty for electrical power grid systems of realistic size with thousands of scenarios. The authors propose several algorithmic and implementation advances in their parallel solver PIPS-IPM for stochastic optimization problems. New developments include a novel, incomplete, augmented, multicore, sparse factorization implemented within the PARDISO linear solver and new multicore- and GPU-based dense matrix implementations. They show improvement on the interprocess communication on Cray XK7 and XC30 systems. PIPS-IPM is used to solve 24-hour horizon power grid problems with up to 1.95 billion decision variables and 1.94 billion constraints on Cray XK7 and Cray XC30, with observed parallel efficiencies and solution times within an operationally defined time interval. To the authors' knowledge, \"real-time\"-compatible performance on a broad range of architectures for this class of problems hasn't been possible prior to this work.","link":"http://www.mendeley.com/research/realtime-stochastic-optimization-complex-energy-systems-highperformance-computers"},{"title":"Optimization for process plans in sheet metal forming","type":"journal","authors":[{"first_name":"Silke","last_name":"Wagner"},{"first_name":"Madan","last_name":"Sathe"},{"first_name":"Olaf","last_name":"Schenk"}],"year":2014,"source":"The International Journal of Advanced Manufacturing Technology","identifiers":{"issn":"0268-3768","doi":"10.1007/s00170-013-5515-7"},"id":"bab29dfb-90d0-310d-8e74-8fd94131ac47","abstract":"Determining a process plan in the early phase of the sheet metal forming process is a mandatory task for a process planner. The objective of a process planner is to find a feasible and cost optimal process plan which, in particular, optimizes the assignment of processing elements to processing steps of the production process. We propose to find such an assignment in an automatic way for all the hole features by splitting the entire task into three subsequent steps. At each step, the combinatorial optimization problem is modeled as a bin packing problem with conflicts, and heuristically solved by a specifically designed ant colony optimizer. It is ensured that, at each step, the process plan is feasible while minimizing the tooling costs. In our computational results, we compare our approach to the existing greedy heuristic when computing a process plan for five different practice-relevant sheet metal parts, and show that we can save up to 50 % of the entire tooling costs.","link":"http://www.mendeley.com/research/optimization-process-plans-sheet-metal-forming-3"},{"title":"Algebraic Multilevel Preconditioner for the Helmholtz Equation in Heterogeneous Media","type":"journal","authors":[{"first_name":"Matthias","last_name":"Bollhöfer"},{"first_name":"Marcus J.","last_name":"Grote"},{"first_name":"Olaf","last_name":"Schenk"}],"year":2009,"source":"SIAM Journal on Scientific Computing","identifiers":{"issn":"1064-8275","sgr":"70350470442","doi":"10.1137/080725702","isbn":"1064-8275","scopus":"2-s2.0-70350470442","pui":"362103988"},"id":"8a2660ff-4765-3f06-b56e-547fd513ae9b","abstract":"An algebraic multilevel (ML) preconditioner is presented for the Helmholtz equation in heterogeneous media. It is based on a multilevel incomplete $LDL^T$ factorization and preserves the inherent (complex) symmetry of the Helmholtz equation. The ML preconditioner incorporates two key components for efficiency and numerical stability: symmetric maximum weight matchings and an inverse-based pivoting strategy. The former increases the block-diagonal dominance of the system, whereas the latter controls $\\|L^{-1}\\|$ for numerical stability. When applied recursively, their combined effect yields an algebraic coarsening strategy, similar to algebraic multigrid methods, even for highly indefinite matrices. The ML preconditioner is combined with a Krylov subspace method and applied as a “black-box” solver to a series of challenging two- and three-dimensional test problems, mainly from geophysical seismic imaging. The numerical results demonstrate the robustness and efficiency of the ML preconditioner, even at higher frequency regimes.","link":"http://www.mendeley.com/research/algebraic-multilevel-preconditioner-helmholtz-equation-heterogeneous-media"},{"title":"Algorithmic performance studies on graphics processing units","type":"journal","authors":[{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Matthias","last_name":"Christen","scopus_author_id":"55225332000"},{"first_name":"Helmar","last_name":"Burkhart","scopus_author_id":"7005750160"}],"year":2008,"source":"Journal of Parallel and Distributed Computing","identifiers":{"scopus":"2-s2.0-51449090534","issn":"07437315","pui":"50230868","pii":"S0743731508000920","sgr":"51449090534","doi":"10.1016/j.jpdc.2008.05.008"},"keywords":["Graphics processing units","Matrix decomposition","Nonlinear optimization","Parallel processing","Sparse direct solvers"],"id":"26929ab7-563c-3a7b-8c18-03f93ed7a6d7","abstract":"We report on our experience with integrating and using graphics processing units (GPUs) as fast parallel floating-point co-processors to accelerate two fundamental computational scientific kernels on the GPU: sparse direct factorization and nonlinear interior-point optimization. Since a full re-implementation of these complex kernels is typically not feasible, we identify the matrix-matrix multiplication as a first natural entry-point for a minimally invasive integration of GPUs. We investigate the performance on the NVIDIA GeForce 8800 multicore chip initially architectured for intensive gaming applications. We exploit the architectural features of the GeForce 8800 GPU to design an efficient GPU-parallel sparse matrix solver. A prototype approach to leverage the bandwidth and computing power of GPUs for these matrix kernel operation is demonstrated resulting in an overall performance of over 110 GFlops/s on the desktop for large matrices and over 38 GFlops/s for sparse matrices arising in real applications. We use our GPU algorithm for PDE-constrained optimization problems and demonstrate that the commodity GPU is a useful co-processor for scientific applications. © 2008 Elsevier Inc. All rights reserved.","link":"http://www.mendeley.com/research/algorithmic-performance-studies-graphics-processing-units-5"},{"title":"Die Notwendigkeit der psychosozialen Begleitung von Eltern in der Neonatologie","type":"generic","authors":[{"first_name":"Nicole","last_name":"Schäfer","scopus_author_id":"57194512807"},{"first_name":"Harald","last_name":"Karutz","scopus_author_id":"8872992300"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"57189007051"}],"year":2017,"source":"Zeitschrift fur Geburtshilfe und Neonatologie","identifiers":{"sgr":"85020386611","scopus":"2-s2.0-85020386611","pui":"616740556","issn":"14391651","doi":"10.1055/s-0043-110056"},"keywords":["neonatal psychology","parent-child-relationship","psychosocial support","risk and protective factors"],"id":"de8ed418-16c6-3de5-acb6-0e5314fa43b6","abstract":"ZuSammeNfaSSuNg Hintergrund Erhebliche Fortschritte in der neonatologischen Medizin haben in den letzten Jahren zu einer Verringerung der Mortalitätsrate und zu einem Anstieg der Morbiditätsrate unter den zu früh-und risikogeborenen Kindern geführt. Häufig ist diese Entwicklung jedoch mit einer zunehmenden Belastung für die gesamte Familie, insbesondere für die Eltern, verbunden. Anhand einer umfangreichen Literaturarbeit wird daher die Not-wendigkeit der psychosozialen Begleitung von Eltern in der Neo-natologie herausgestellt. Methodik In den Datenbanken Pubmed, Psyndex, CINAHl und medpilot wurde zunächst eine systematische Literaturrecher-che durchgeführt. Um weitere relevante Publikationen zu fin-den, wurden außerdem die Referenzlisten der gefundenen Artikel überprüft. Eine anschließende Freitextsuche hatte die Ergänzung der Schlagwortsuche zum Ziel. Insgesamt konnten auf diese Weise 78 Veröffentlichungen aus den Jahren von 1975 bis 2015 in die Studie einbezogen werden. Ergebnisse Die Bedeutung der psychosozialen Begleitung von Eltern in der Neonatologie lässt sich anhand der ausgewerteten Fachliteratur eindrucksvoll belegen. Allerdings fällt auf, dass die Notwendigkeit eines Assessments als Grundlage einer den indivi-duellen Bedürfnissen der Familie entsprechenden Begleitung zwar bekannt ist, die Verwendung von validierten Screeninginstrumen-ten offenbar jedoch noch nicht zum Standard gehört. Ferner wird deutlich, dass der Bedarf an psychosozialer Unterstützung seitens der Eltern nicht allein vom medizinischen Risiko des Kindes abhängt. Schlussfolgerungen Die vorliegenden Erkenntnisse implizie-ren insbesondere die Herausforderung, unter Berücksichtigung der in der Entwicklung befindlichen Eltern-Kind-Einheit, in ei-nem Gesundheitssystem mit eingeschränkten Ressourcen und vor dem Hintergrund gesundheitsökonomischer Vorgaben, dennoch eine hoch individuelle Betreuung betroffener Familien möglich zu machen. Mitunter intuitiv ausgebildete Konzepte sollten in Zukunft weiter wissenschaftlich fundiert werden. Beiträge aus den Bereichen der Psychologie und Bindungsfor-schung sind dabei zu berücksichtigen. abStr ac t Background Advances in neonatal care have reduced mortality","link":"http://www.mendeley.com/research/die-notwendigkeit-der-psychosozialen-begleitung-von-eltern-der-neonatologie"},{"title":"An auction-based weighted matching implementation on massively parallel architectures","type":"journal","authors":[{"first_name":"Madan","last_name":"Sathe","scopus_author_id":"25639887700"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Helmar","last_name":"Burkhart","scopus_author_id":"7005750160"}],"year":2012,"source":"Parallel Computing","identifiers":{"issn":"01678191","sgr":"84870016328","doi":"10.1016/j.parco.2012.09.001","pii":"S0167819112000750","scopus":"2-s2.0-84870016328","pui":"366130144"},"keywords":["Auction algorithm","Bipartite graph matching","Combinatorial scientific computing","Hybrid MPI-OpenMP programming","Multicore applications","Performance studies"],"id":"3ef33653-4ead-3d77-9657-0f54987d57c8","abstract":"Maximum weighted matchings represent a fundamental kernel in massive graph analysis and occur in a wide range of real-life applications. Here, a parallel auction-based matching algorithm is developed, which is able to tackle matchings in very large, dense, and sparse bipartite graphs. It will be demonstrated that the convergence of the auction algorithm crucially depends on two different ε-scaling strategies. The auction algorithm including the ε-scaling strategies has been implemented using a hybrid MPI-OpenMP programming model, and its performance is validated in various applications from bioinformatics, computer vision, and sparse linear algebra. It is concluded that for dense bipartite graphs, the auction algorithm scales well, and for sparse bipartite graphs at least a substantial speedup is achieved against alternative approaches that are based on augmenting path algorithms. © 2012 Elsevier B.V. All rights reserved.","link":"http://www.mendeley.com/research/auctionbased-weighted-matching-implementation-massively-parallel-architectures"},{"title":"PATUS for convenient high-performance stencils: Evaluation in earthquake simulations","type":"conference_proceedings","authors":[{"first_name":"Matthias","last_name":"Christen","scopus_author_id":"55225332000"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Yifeng","last_name":"Cui","scopus_author_id":"18436728700"}],"year":2012,"source":"International Conference for High Performance Computing, Networking, Storage and Analysis, SC","identifiers":{"sgr":"84877717516","scopus":"2-s2.0-84877717516","pui":"368902859","isbn":"9781467308069","issn":"21674329","doi":"10.1109/SC.2012.95"},"id":"9887387b-f347-3bd8-b58b-43448e9d12a4","abstract":"PATUS is a code generation and auto-tuning framework for stencil computations targeting modern multi and many-core processors. The goals of the framework are productivity and portability for achieving high performance on the target platform. Its stencil specification language allows the programmer to express the computation in a concise way independently of hardware architecture-specific details. Thus, it increases the programmer productivity by removing the need for manual low-level tuning. We illustrate the impact of the stencil code generation in seismic applications, for which both weak and strong scaling are important. We evaluate the performance by focusing on a scalable discretization of the wave equation and testing complex simulation types of the AWP-ODC code to aim at excellent parallel efficiency, preparing for petascale 3-D earthquake calculations.","link":"http://www.mendeley.com/research/patus-convenient-highperformance-stencils-evaluation-earthquake-simulations"},{"title":"PSPIKE: A parallel hybrid sparse linear system solver","type":"conference_proceedings","authors":[{"first_name":"Murat","last_name":"Manguoglu","scopus_author_id":"23994437100"},{"first_name":"Ahmed H.","last_name":"Sameh","scopus_author_id":"7004047002"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"}],"year":2009,"source":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","identifiers":{"isbn":"3642038689","scopus":"2-s2.0-70350637491","issn":"03029743","pui":"355548031","sgr":"70350637491","doi":"10.1007/978-3-642-03869-3_74"},"keywords":["Direct solvers","Hybrid solvers","Krylov subspace methods","Sparse linear systems"],"id":"9bf7ad87-df34-3043-98b5-73c66cf00bea","abstract":"The availability of huge-scale computing platforms comprised of tells\\nof thousands of multicore processors motivates the need for the next\\ngeneration of highly scalable sparse linear system solvers. These\\nsolvers must optimize parallel performance, processor (serial)\\nperformance; as well as memory requirements, while being robust across\\nbroad classes of applications and systems. In this paper, we present; a\\nnew parallel solver that combines the desirable characteristics of\\ndirect methods (robustness) and effective iterative solvers (low\\ncomputational cost), while alleviating their drawbacks (memory\\nrequirements, lack of robustness). Our proposed hybrid solver is based\\non tire general sparse solver PARDISO; and the ``Spike{''} family of\\nhybrid solvers. The resulting algorithm, called PSPIKE, is as robust as\\ndirect solvers, more reliable than classical preconditioned Krylov\\nsubspace methods, and much more scalable than direct sparse solvers. We\\nsupport; our performance and parallel scalability claims using detailed\\nexperimental studies and comparison with direct solvers, as well as\\nclassical preconditioned Krylov methods.","link":"http://www.mendeley.com/research/pspike-parallel-hybrid-sparse-linear-system-solver"},{"title":"Task-Queue Based Hybrid Parallelism: A Case Study.","type":"conference_proceedings","authors":[{"first_name":"Karl","last_name":"Fürlinger"},{"first_name":"Olaf","last_name":"Schenk"},{"first_name":"Michael","last_name":"Hagemann"}],"year":2004,"source":"Euro-Par","identifiers":{"isbn":"3-540-22924-8","scopus":"2-s2.0-35048902119","issn":"03029743 16113349","pui":"39746537","sgr":"35048902119"},"id":"e4b5eb51-61ea-3c31-9a0e-e3bd8989c0e3","abstract":"In this paper we report on our experiences with hybrid parallelism in PARDISO, a high-performance sparse linear solver. We start with the OpenMP-parallel numerical factorization algorithm and reorganize it using a central dynamic task queue to be able to add message passing functionality. The hybrid version allows the solver to run on a larger number of processors in a cost effective way with very reasonable performance. A speed-up of more than nine running on a four-node quad Itanium 2 SMP cluster is achieved in spite of the fact that a large potential to minimize MPI communication is not yet exploited in the first version of the implementation. ? Springer-Verlag 2004.","link":"http://www.mendeley.com/research/taskqueue-based-hybrid-parallelism-case-study"},{"title":"Application of parallel sparse direct methods in semiconductor device and process simulation","type":"conference_proceedings","authors":[{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Klaus","last_name":"Gärtner","scopus_author_id":"7005597145"},{"first_name":"Wolfgang","last_name":"Fichtner","scopus_author_id":"7102619386"}],"year":1999,"source":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","identifiers":{"isbn":"3540659692","scopus":"2-s2.0-67649638695","issn":"16113349","pui":"608397292","sgr":"67649638695","doi":"10.1007/BFb0094923"},"id":"f284d1dd-42fc-36bf-b6a7-d99f58d06f6d","link":"http://www.mendeley.com/research/application-parallel-sparse-direct-methods-semiconductor-device-process-simulation"},{"title":"TagFS: Bringing Semantic Metadata to the Filesystem","type":"conference_proceedings","authors":[{"first_name":"Simon","last_name":"Schenk"},{"first_name":"Olaf","last_name":"Görlitz"},{"first_name":"Steffen","last_name":"Staab"}],"year":2006,"source":"ESWC 2006","keywords":["ファイルシステム"],"id":"cfa3df82-268f-303a-bf72-a8e02b5f6ebc","abstract":"Tagging has recently become very popular because of in- \\nternet applications like del.icio.us and flickr which allow easy \\ncategorisation of personal information plus sharing it with \\na large community. These tools are centralised internet ser- \\nvices enabling users to collaborate, organise and share per- \\nsonal information. Most tagging applications are tailored to \\na specific set of information ob jects that the user manages \\nonline at a centralised storage site. To push tagging towards \\nbecoming a significant part of user's everyday work it should \\nbe integrated in a broad range of desktop applications. To- \\nday the tool most commonly used for structuring knowledge \\namong average users is the filesystem. In the following we \\nintroduce TagFS which allows tagging of files as well as tag- \\nbased browsing for arbitrary information ob jects on top of \\nthe local filesystem. Tagging information is stored in RDF \\nin order to enable easy integration with semantic web and \\nsemantic desktop applications. \\nAs a use case, attending a conference is a scenario in which \\nmany information ob jects become relevant: photos taken at \\nthe conference, electronic tickets and reservations, electronic \\npapers, etc. However, when surveying latest photo shots for \\nsharing on a photo server, when compiling the latest travel \\ncost statements, or when sorting the papers to be read by \\ncolleagues, hierarchical organisation of information ob jects \\nis inconvenient. In contrast, tags allow for structuring an \\ninformation ob ject into the different dimensions for which it \\nis relevant. \\n","link":"http://www.mendeley.com/research/tagfs-bringing-semantic-metadata-filesystem"},{"title":"PATUS: A code generation and autotuning framework for parallel iterative stencil computations on modern microarchitectures","type":"conference_proceedings","authors":[{"first_name":"Matthias","last_name":"Christen","scopus_author_id":"55225332000"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Helmar","last_name":"Burkhart","scopus_author_id":"7005750160"}],"year":2011,"source":"Proceedings - 25th IEEE International Parallel and Distributed Processing Symposium, IPDPS 2011","identifiers":{"sgr":"80053238973","scopus":"2-s2.0-80053238973","pui":"362644653","isbn":"9780769543857","issn":"1530-2075","doi":"10.1109/IPDPS.2011.70"},"keywords":["autotuning","code generation","high performance computing","stencil computations"],"id":"ec7d0646-cf07-3dbb-b05e-215d5ee74bfb","abstract":"Stencil calculations comprise an important class of kernels in many scientific computing applications ranging from simple PDE solvers to constituent kernels in multigrid methods as well as image processing applications. In such types of solvers, stencil kernels are often the dominant part of the computation, and an efficient parallel implementation of the kernel is therefore crucial in order to reduce the time to solution. However, in the current complex hardware micro architectures, meticulous architecture-specific tuning is required to elicit the machine's full compute power. We present a code generation and auto-tuning framework textscPatus for stencil computations targeted at multi- and many core processors, such as multicore CPUs and graphics processing units, which makes it possible to generate compute kernels from a specification of the stencil operation and a parallelization and optimization strategy, and leverages the auto tuning methodology to optimize strategy-dependent parameters for the given hardware architecture.","link":"http://www.mendeley.com/research/patus-code-generation-autotuning-framework-parallel-iterative-stencil-computations-modern-microarchi"},{"title":"Solving Bi-objective many-constraint bin packing problems in automobile sheet metal forming processes","type":"conference_proceedings","authors":[{"first_name":"Madan","last_name":"Sathe","scopus_author_id":"25639887700"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Helmar","last_name":"Burkhart","scopus_author_id":"7005750160"}],"year":2010,"source":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","identifiers":{"issn":"03029743","sgr":"78650734442","doi":"10.1007/978-3-642-01020-0_22","isbn":"3642010199","scopus":"2-s2.0-78650734442","pui":"361019671"},"id":"f04d1591-0977-3b4b-8157-11e90715f6b5","link":"http://www.mendeley.com/research/solving-biobjective-manyconstraint-bin-packing-problems-automobile-sheet-metal-forming-processes"},{"title":"Parallelized Dimensional Decomposition for Large-Scale Dynamic Stochastic Economic Models","type":"conference_proceedings","authors":[{"first_name":"Aryan","last_name":"Eftekhari"},{"first_name":"Simon","last_name":"Scheidegger"},{"first_name":"Olaf","last_name":"Schenk"}],"year":2017,"source":"Proceedings of the Platform for Advanced Scientific Computing Conference on   - PASC '17","identifiers":{"arxiv":"arXiv:1603.09436","sgr":"85025827406","scopus":"2-s2.0-85025827406","pui":"617525080","isbn":"9781450350624","issn":"15232867","doi":"10.1145/3093172.3093234"},"id":"d7d69b75-59aa-386b-a487-5f5034442b03","abstract":"Fault-tolerant distributed algorithms play an important role in many critical/high-availability applications. These algorithms are notori-ously difficult to implement correctly, due to asynchronous com-munication and the occurrence of faults, such as the network drop-ping messages or computers crashing. We introduce PSYNC, a domain specific language based on the Heard-Of model, which views asynchronous faulty systems as syn-chronous ones with an adversarial environment that simulates asyn-chrony and faults by dropping messages. We define a runtime sys-tem for PSYNC that efficiently executes on asynchronous networks. We formalize the relation between the runtime system and PSYNC in terms of observational refinement. The high-level lockstep ab-straction introduced by PSYNC simplifies the design and imple-mentation of fault-tolerant distributed algorithms and enables auto-mated formal verification. We have implemented an embedding of PSYNC in the SCALA programming language with a runtime system for asynchronous networks. We show the applicability of PSYNC by implementing several important fault-tolerant distributed algorithms and we com-pare the implementation of consensus algorithms in PSYNC against implementations in other languages in terms of code size, runtime efficiency, and verification.","link":"http://www.mendeley.com/research/parallelized-dimensional-decomposition-largescale-dynamic-stochastic-economic-models"},{"title":"Inertia-Revealing Preconditioning For Large-Scale Nonconvex Constrained Optimization","type":"journal","authors":[{"first_name":"Olaf","last_name":"Schenk"},{"first_name":"Andreas","last_name":"Wächter"},{"first_name":"Martin","last_name":"Weiser"}],"year":2009,"source":"SIAM Journal on Scientific Computing","identifiers":{"sgr":"67349213103","scopus":"2-s2.0-67349213103","pui":"354812459","issn":"1064-8275","doi":"10.1137/070707233"},"id":"0cb9cc14-9b66-3153-b545-1afd21ac1b82","abstract":"Fast nonlinear programming methods following the all-at-once approach usually employ Newton’s method for solving linearized Karush–Kuhn–Tucker (KKT) systems. In nonconvex problems, the Newton direction is guaranteed to be a descent direction only if the Hessian of the Lagrange function is positive definite on the nullspace of the active constraints; otherwise some modifications to Newton’s method are necessary. This condition can be verified using the signs of the KKT eigenvalues (inertia), which are usually available from direct solvers for the arising linear saddle point problems. Iterative solvers are mandatory for very large-scale problems, but in general they do not provide the inertia. Here we present a preconditioner based on a multilevel incomplete LBLT factorization, from which an approximation of the inertia can be obtained. The suitability of the heuristics for application in optimization methods is verified on an interior point method applied to the CUTE and COPS test problems, on large-scale three-dimensional (3D) PDE- constrained optimal control problems, and on 3D PDE-constrained optimization in biomedical cancer hyperthermia treatment planning. The efficiency of the preconditioner is demonstrated on convex and nonconvex problems with 1503 state variables and 1502 control variables, both subject to bound constraints.","link":"http://www.mendeley.com/research/inertiarevealing-preconditioning-largescale-nonconvex-constrained-optimization"},{"title":"Towards the next generation of multiperiod optimal power flow solvers","authors":[{"first_name":"Drosos","last_name":"Kourounis","scopus_author_id":"15735165800"},{"first_name":"Alexander","last_name":"Fuchs","scopus_author_id":"57016175900"},{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"}],"year":2018,"source":"IEEE Transactions on Power Systems","identifiers":{"issn":"08858950","sgr":"85040054302","doi":"10.1109/TPWRS.2017.2789187","scopus":"2-s2.0-85040054302","pui":"620136696"},"keywords":["Artificial neural networks","Couplings","Generators","IP networks","Multiperiod optimal power flow","Niobium","Optimization","Planning","interior point methods","power system planning"],"id":"183dc01c-d1cd-3da8-b53b-1d9c8f965565","abstract":"IEEE Distributed energy storage devices are commonly employed as an effective approach for addressing operational challenges introduced by the large scale integration of renewables. However, the modeling of storage devices results in intertemporal coupling of the individual optimal power flow (OPF) problems defined at each subdivision of the time period of interest. The resulting multiperiod optimal power flow (MPOPF) problem becomes intractable prohibiting this way forecasting and planning over long time periods. Interior point (IP) methods have been extensively employed for the solution of OPF and MPOPF problems. This work proposes an efficient IP algorithm, MPFOPT, particularly designed for MPOPF problems. The structure of the KKT system associated with the optimality conditions is revisited, and a Schur-complement-based approach tailored to its structure is proposed. Through benchmark cases involving power-grid models of increasing complexity, the MPFOPT algorithm is demonstrated to provide several orders of magnitude faster solution times than standard optimization methods like IPOPT, MIPS and KNITRO, using significantly fewer amounts of memory.","link":"http://www.mendeley.com/research/towards-next-generation-multiperiod-optimal-power-flow-solvers"},{"title":"General-Purpose Sparse Matrix Building Blocks using the NVIDIA CUDA Technology Platform","type":"journal","authors":[{"first_name":"Matthias","last_name":"Christen"},{"first_name":"Olaf","last_name":"Schenk"},{"first_name":"Helmar","last_name":"Burkhart"}],"year":2007,"source":"Science","id":"68307212-b9e4-3b11-9290-99bb8d521ff2","abstract":"We report on our experience with integrating and using graphics processing units (GPUs) as fast parallel floating- point co-processors to accelerate two fundamental computational scientific kernels on the GPU: sparse direct factorization and non- linear interior-point optimization. Since a full re-implementation of these complex kernels is typically not feasible, we identify e.g. the matrix-matrix multiplication as a first natural entry-point for a minimally invasive integration of GPUs. We investigate the performance on the NVIDIA GeForce 8800 multicore chip. We exploit the architectural features of the GeForce 8800 GPU to design an efficientGPU-parallel sparse matrix solver. A prototype approach to leverage the bandwidth and computing power of GPUs for these matrix kernel operation is demonstrated resulting in an overall performance of over 110 GFlops/s on the desktop for large matrices. We use our GPU algorithm for PDE-constrained optimization problems and demonstrate that the commodity GPU is a useful co-processor for scientific applications.","link":"http://www.mendeley.com/research/generalpurpose-sparse-matrix-building-blocks-using-nvidia-cuda-technology-platform-3"},{"title":"Matching-based preprocessing algorithms to the solution of saddle-point problems in large-scale nonconvex interior-point optimization","type":"journal","authors":[{"first_name":"Olaf","last_name":"Schenk","scopus_author_id":"6701544373"},{"first_name":"Andreas","last_name":"Wächter","scopus_author_id":"7004014085"},{"first_name":"Michael","last_name":"Hagemann","scopus_author_id":"56212964400"}],"year":2007,"source":"Computational Optimization and Applications","identifiers":{"issn":"09266003","sgr":"34248193895","doi":"10.1007/s10589-006-9003-y","isbn":"0926-6003","scopus":"2-s2.0-34248193895","pui":"46723404"},"keywords":["Interior-point method","Maximum weight matching","Nonconvex nonlinear programming","Numerical linear algebra","Saddle-point problem"],"id":"b47daba4-0eaf-3e81-8deb-e517f58dcb24","abstract":"Interior-point methods are among the most efficient approaches for solving large-scale nonlinear programming problems. At the core of these methods, highly ill-conditioned symmetric saddle-point problems have to be solved. We present combinatorial methods to preprocess these matrices in order to establish more favorable numerical properties for the subsequent factorization. Our approach is based on symmetric weighted matchings and is used in a sparse direct LDLT factorization method where the pivoting is restricted to static supernode data structures. In addition, we will dynamically expand the supernode data structure in cases where additional fill-in helps to select better numerical pivot elements. This technique can be seen as an alternative to the more traditional threshold pivoting techniques. We demonstrate the competitiveness of this approach within an interior-point method on a large set of test problems from the CUTE and COPS sets, as well as large optimal control problems based on partial differential equations. The largest nonlinear optimization problem solved has more than 12 million variables and 6 million constraints.","link":"http://www.mendeley.com/research/matchingbased-preprocessing-algorithms-solution-saddlepoint-problems-largescale-nonconvex-interiorpo"}]
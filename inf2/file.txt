[{"title":"Map reduce program synthesis","type":"conference_proceedings","authors":[{"first_name":"C","last_name":"Smith"},{"first_name":"A","last_name":"Albarghouthi"}],"year":2016,"source":"Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)","identifiers":{"isbn":"9781450342612","sgr":"84975886641","pui":"610963123","doi":"10.1145/2908080.2908102"},"id":"1f07f28c-c093-30e3-8d6a-9b80ba2cb2de","created":"2018-03-04T13:37:40.735Z","profile_id":"2a9c55a5-f956-32e1-ba55-07501c4bb267","last_modified":"2018-03-04T13:37:40.735Z","abstract":"By abstracting away the complexity of distributed systems, large-scale data processing platforms-MapReduce, Hadoop, Spark, Dryad, etc.-have provided developers with simple means for harnessing the power of the cloud. In this paper, we ask whether we can automatically synthesize MapReduce-style distributed programs from input-output examples. Our ultimate goal is to enable end users to specify large-scale data analyses through the simple interface of examples. We thus present a new algorithm and tool for synthesizing programs composed of efficient data-parallel operations that can execute on cloud computing infrastructure. We evaluate our tool on a range of real-world big-data analysis tasks and general computations. Our results demonstrate the efficiency of our approach and the small number of examples it requires to synthesize correct, scalable programs. © 2016 ACM."},{"title":"Map reduce program synthesis","type":"conference_proceedings","authors":[{"first_name":"Calvin","last_name":"Smith"},{"first_name":"Aws","last_name":"Albarghouthi"}],"year":2016,"source":"Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)","identifiers":{"isbn":"9781450342612","sgr":"84975886641","pui":"610963123","scopus":"2-s2.0-84975886641","doi":"10.1145/2908080.2908102"},"keywords":["Computational linguistics;Computer programming lan"],"id":"89605bcb-7095-38f2-8bac-ec0348406cb2","created":"2018-03-04T13:37:40.765Z","profile_id":"2a9c55a5-f956-32e1-ba55-07501c4bb267","last_modified":"2018-03-04T13:37:40.765Z","abstract":"By abstracting away the complexity of distributed systems, large-scale data processing platforms-MapReduce, Hadoop, Spark, Dryad, etc.-have provided developers with simple means for harnessing the power of the cloud. In this paper, we ask whether we can automatically synthesize MapReduce-style distributed programs from input-output examples. Our ultimate goal is to enable end users to specify large-scale data analyses through the simple interface of examples. We thus present a new algorithm and tool for synthesizing programs composed of efficient data-parallel operations that can execute on cloud computing infrastructure. We evaluate our tool on a range of real-world big-data analysis tasks and general computations. Our results demonstrate the efficiency of our approach and the small number of examples it requires to synthesize correct, scalable programs. &copy; 2016 ACM."},{"title":"DFA Minimization in Map-Reduce","type":"conference_proceedings","authors":[{"first_name":"Gösta","last_name":"Grahne"},{"first_name":"Shahab","last_name":"Harrafi"},{"first_name":"Iraj","last_name":"Hedayati"},{"first_name":"Ali","last_name":"Moallemi"}],"year":2016,"source":"BeyondMR '16 Proceedings of the 3rd ACM SIGMOD Workshop on Algorithms and Systems for MapReduce and Beyond","identifiers":{"isbn":"9781450343114","doi":"http://dx.doi.org/10.1145/2926534.2926537"},"keywords":["automata","communicationi cost","dfa minimization","map-reduce"],"id":"6f1bc29e-07aa-3ad6-b14d-ba83b428fede","created":"2018-03-04T13:37:40.820Z","profile_id":"2a9c55a5-f956-32e1-ba55-07501c4bb267","last_modified":"2018-03-04T13:37:40.820Z","abstract":"We describe Map-Reduce implementations of two of the most prominent DFA minimization methods, namely Moore's and Hopcroft's algorithms. Our analysis shows that the one based on Hopcroft's algorithm is more efficient, both in terms of running time and communication cost. This is validated by our extensive experiments on various types of DFA's, with up to 217 states. It also turns out that both algorithms are sensitive to skewed input, the Hopcroft's algorithm being intrinsically so."},{"title":"Map-reduce-merge","type":"conference_proceedings","authors":[{"first_name":"Hung-chih","last_name":"Yang"},{"first_name":"Ali","last_name":"Dasdan"},{"first_name":"Ruey-Lung","last_name":"Hsiao"},{"first_name":"D. Stott","last_name":"Parker"}],"year":2007,"source":"Proceedings of the 2007 ACM SIGMOD international conference on Management of data  - SIGMOD '07","identifiers":{"isbn":"9781595936868","issn":"<null>","doi":"10.1145/1247480.1247602"},"id":"d86c5295-23f3-325d-9adc-910a564d485b","created":"2018-03-04T13:37:41.055Z","profile_id":"2a9c55a5-f956-32e1-ba55-07501c4bb267","last_modified":"2018-03-04T13:37:41.055Z","abstract":"Map-Reduce is a programming model that enables easy development of scalable parallel applications to process a vast amount of data on large clusters of commodity machines. Through a simple interface with two functions, map and reduce, this model facilitates parallel implementation of many real-world tasks such as data processing jobs for search engines and machine learning. However,this model does not directly support processing multiple related heterogeneous datasets. While processing relational data is a common need, this limitation causes difficulties and/or inefficiency when Map-Reduce is applied on relational operations like joins. We improve Map-Reduce into a new model called Map-Reduce-Merge. It adds to Map-Reduce a Merge phase that can efficiently merge data already partitioned and sorted (or hashed) by map and reduce modules. We also demonstrate that this new model can express relational algebra operators as well as implement several join algorithms."},{"title":"Map Reduce Design Patterns","type":"book","authors":[{"first_name":"R","last_name":"Bott"}],"year":2014,"source":"Igarss 2014","identifiers":{"pmid":"15003161","arxiv":"arXiv:1011.1669v3","isbn":"9780874216561","issn":"0717-6163","doi":"10.1007/s13398-014-0173-7.2"},"keywords":["Bott"],"id":"15c3fce2-aa60-3f8c-b811-93902be62871","created":"2018-03-04T13:37:41.312Z","profile_id":"2a9c55a5-f956-32e1-ba55-07501c4bb267","last_modified":"2018-03-04T13:37:41.312Z","abstract":"Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed."}]